{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### uses vgg.json file to create binary images of the ground truth fretboard segmentations\n",
    "\n",
    "import cv2 as cv\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# expects fretboard dataset to be in data folder on same level as tabs_generator folder\n",
    "train_str = \"test\" # change to train or test to perform on respective data\n",
    "dataset_path = \"../data/fretboard_dataset/\"\n",
    "images_path = f\"../data/fretboard_dataset/fretboard_frames_{train_str}/\"\n",
    "image_fns = os.listdir(images_path)\n",
    "json_fn = os.path.join(dataset_path, f\"fretboard_labels_{train_str}_vgg.json\")\n",
    "f = open(json_fn)\n",
    "data = json.load(f) # data is dict of json contents\n",
    "k = list(data.keys())\n",
    "\n",
    "for i, fn in enumerate(image_fns):\n",
    "    img_path = os.path.join(images_path, fn)\n",
    "    out_path = os.path.join(images_path, \"annotated_\"+fn)\n",
    "    img = np.asarray(Image.open(img_path)) # loads images w/ range of 0:255\n",
    "    x_list = data[k[i]][\"regions\"][\"0\"][\"shape_attributes\"][\"all_points_x\"] # list of rectangle coordinates\n",
    "    y_list = data[k[i]][\"regions\"][\"0\"][\"shape_attributes\"][\"all_points_y\"]\n",
    "    x_list.pop(-1) # remove duplicate of first coordinate from end of lists\n",
    "    y_list.pop(-1)\n",
    "    poly_corners = np.asarray([list(zip(x_list, y_list))], dtype=np.int32) # repackage into np array w/ correct dtype\n",
    "    new_img = np.zeros((img.shape[0], img.shape[1]), np.uint8) # create empty binary image mask\n",
    "    new_img = cv.fillPoly(new_img, poly_corners, 255) # fill polygon of rectangle coordinates\n",
    "    Image.fromarray(new_img).save(out_path) # save output image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "from scipy.ndimage import median_filter\n",
    "\n",
    "dataset_path = \"../data/fretboard_dataset/\"\n",
    "garrett_path = \"../data/new_dataset/garrett_amogus/\"\n",
    "frames_path = \"../data/fretboard_dataset/fretboard_frames_train/\"\n",
    "test_frames_path = \"../data/fretboard_dataset/fretboard_frames_test/33_4.png\" # canny doesn't find the strings very well for this guitar\n",
    "data = {}\n",
    "out = \"../data/fretboard_dataset/train.json\"\n",
    "p = frames_path\n",
    "frames_fn_list = os.listdir(p)\n",
    "train_fns = []\n",
    "for f in frames_fn_list:\n",
    "    if \"annotated\" not in f:\n",
    "        train_fns.append(f)\n",
    "\n",
    "frame_fn = train_fns[111]\n",
    "for frame_fn in train_fns:\n",
    "    img = cv.imread(os.path.join(p, frame_fn))\n",
    "    gray = np.uint8(cv.cvtColor(img, cv.COLOR_BGR2GRAY))\n",
    "    gamma = 0.5\n",
    "    lookUpTable = np.empty((1,256), np.uint8)\n",
    "    for i in range(256): # gamma correction for contrast enhancement\n",
    "        lookUpTable[0,i] = np.clip(pow(i / 255.0, gamma) * 255.0, 0, 255)\n",
    "        grayCE = cv.LUT(gray, lookUpTable)\n",
    "    blurred = cv.GaussianBlur(grayCE, (0,0), 2.0)\n",
    "    unsharp = cv.addWeighted(grayCE, 3.0, blurred, -2, 0) # unsharp masking\n",
    "    # plt.figure(figsize=(12,12))\n",
    "    # plt.imshow(gray.astype(np.uint8), cmap=\"gray\")\n",
    "    # plt.show()\n",
    "    # plt.figure(figsize=(12,12))\n",
    "    # plt.imshow(unsharp.astype(np.uint8), cmap=\"gray\")\n",
    "    # plt.show()\n",
    "    canny = cv.Canny(unsharp.astype(np.uint8), 150, 170, apertureSize=3, L2gradient=True)\n",
    "    cdstP = cv.cvtColor(canny, cv.COLOR_GRAY2RGB)\n",
    "    linesP = cv.HoughLinesP(canny, 1, np.pi / 180, 50, None, 6, 10)\n",
    "    linesP = linesP[:400,:,:] # get top N lines\n",
    "    linesP = linesP.ravel().tolist() # vectorize coordinates\n",
    "    data[frame_fn] = linesP\n",
    "    # if linesP is not None:\n",
    "    #     for i in range(0, len(linesP)):\n",
    "    #         l = linesP[i][0]\n",
    "    #         cv.line(cdstP, (l[0], l[1]), (l[2], l[3]), (0,0,255), 3, cv.LINE_AA)\n",
    "\n",
    "with open(out, \"w\") as outfile:\n",
    "    json.dump(data, outfile)\n",
    "# plt.figure(figsize=(12,12))\n",
    "# plt.imshow(cdstP, cmap=\"gray\")\n",
    "# plt.title(\"Probabilistic Hough Transform\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea for finding the fretboard:\n",
    "1. create ideal locations of the fretboard markers\n",
    "2. detect features using corner detection or blob detection\n",
    "3. keep top N features\n",
    "4. feed these features' coordinates into a neural network to find fretboard??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[599, 911, 937, 631]\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "# paths\n",
    "dataset_path = \"../data/fretboard_dataset/\"\n",
    "train_path = os.path.join(dataset_path, \"fretboard_frames_train\")\n",
    "json_fn = os.path.join(dataset_path, f\"fretboard_labels_train_vgg.json\")\n",
    "image_fns = os.listdir(images_path)\n",
    "train_fns = []\n",
    "for f in image_fns:\n",
    "    if \"annotated\" not in f:\n",
    "        train_fns.append(f)\n",
    "\n",
    "def load_random_sample():\n",
    "    f = random.choice(train_fns)\n",
    "    img = cv.imread(os.path.join(train_path, f))\n",
    "    gray = np.uint8(cv.cvtColor(img, cv.COLOR_BGR2GRAY))\n",
    "    gamma = 1.5\n",
    "    lookUpTable = np.empty((1,256), np.uint8)\n",
    "    for i in range(256): # gamma correction for contrast enhancement\n",
    "        lookUpTable[0,i] = np.clip(pow(i / 255.0, gamma) * 255.0, 0, 255)\n",
    "        grayCE = cv.LUT(gray, lookUpTable)\n",
    "    lap = cv.Laplacian(gray, cv.CV_64F)\n",
    "    sharp = grayCE - 0.3 * lap # unsharp masking\n",
    "    plt.figure(figsize=(12,12))\n",
    "    plt.imshow(sharp.astype(np.uint8), cmap=\"gray\")\n",
    "    plt.show()\n",
    "    canny = cv.Canny(sharp.astype(np.uint8), 200, 250, apertureSize=3, L2gradient=True)\n",
    "    cdstP = cv.cvtColor(canny, cv.COLOR_GRAY2RGB)\n",
    "    linesP = cv.HoughLinesP(canny, 1, np.pi / 180, 50, None, 2, 15)\n",
    "    linesP = linesP[:400,:,:] # get top N lines\n",
    "    if linesP is not None:\n",
    "        for i in range(0, len(linesP)):\n",
    "            l = linesP[i][0]\n",
    "            cv.line(cdstP, (l[0], l[1]), (l[2], l[3]), (0,0,255), 3, cv.LINE_AA)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
